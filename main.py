# -*- coding: utf-8 -*-
"""mnist_self_implement.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ge-Kv__rNc5lF1ak8M0EytyMv6KbaEyH
"""
import numpy as np
from util.util import accuracy
from data.dataset import get_mnist, dataset
from util.layers import Cross_Entropy
from model import NN


def main():
    epochs = 20
    log_step = 100
    batch_size = 64
    x_train, x_val, y_train, y_val = get_mnist()
    mnist_nn = NN(input_size = 784, output_size = 10)
    train_dataset = dataset(x_train, y_train, batch_size=batch_size)
    test_dataset = dataset(x_val, y_val, batch_size=batch_size)

    for epoch in range(epochs):
        loss_ = []
        loss = Cross_Entropy()
        for step, (image, label) in enumerate(train_dataset):
            x, y = image.T, label.T
            
            output = mnist_nn.forward(x)
            ce_loss = loss.forward(output, y)
            mnist_nn.backward(loss.backward(y))
            mnist_nn.update()
            
            loss_.append(ce_loss) 
            if step % log_step == 0:
                print('[epoch {}/{}] step: {}/{}, loss: {}'.format(epoch, epochs, step, len(x_train)//batch_size, sum(loss_)/len(loss_)))
                
        mnist_nn.schduler_step(epoch=epochs)
        test_acc = accuracy(mnist_nn, test_dataset)
        train_acc = accuracy(mnist_nn, train_dataset)
        epoch_loss = sum(loss_)/len(loss_)
        print('train acc: {}, test acc: {}, loss: {}'.format(train_acc, test_acc, epoch_loss))
    
if __name__ == '__main__':
    main()