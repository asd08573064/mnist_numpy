# -*- coding: utf-8 -*-
"""mnist_self_implement.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ge-Kv__rNc5lF1ak8M0EytyMv6KbaEyH
"""
import numpy as np
import random

from sklearn.model_selection import train_test_split
from util.util import to_categorical
from util.activation import cross_entropy
from network import NN
from scipy.io import loadmat


epochs = 20
log_step = 50

mnist = loadmat('./data/mnist-original.mat')
x = mnist['data'].T
x = (x/255.).astype('float32')

y = mnist['label'].T.flatten()
y = to_categorical(y)

x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.15, random_state=42)



def accuracy(model, x, y):
    correct = 0
    for i in range(y.shape[0]):
        index = model.forward(x[i])
        one_hot = 0
        for digit in range(y[i].shape[0]):
            predict = np.argmax(index)
            if y[i][digit] == 1:
                one_hot = digit
                break
        if predict == one_hot:
            correct += 1
    return correct/y.shape[0]



mnist_nn = NN(input_size = 784, hidden_1_size = 700, hidden_2_size = 700,output_size = 10)

for epoch in range(epochs):
    loss_ = []
    step = 0
    for image, label in zip(x_train, y_train):
        image = np.expand_dims(image, axis=1)  
        label = np.expand_dims(label, axis=1)  
        
        output = mnist_nn.forward(image)
        loss = cross_entropy(output, label)
        loss_.append(loss)
        mnist_nn.backward(label)
        mnist_nn.update()
        
        if step % log_step == 0:
            print('epoch: {} step: {}/{}, loss: {}'.format(epoch, step, len(x_train), sum(loss_)/len(loss_)))
        step+=1

    print('epoch:', epoch)
    acc = accuracy(mnist_nn, x_val, y_val)
    epoch_loss = sum(loss_)/len(loss_)
    print('acc: {}, loss: {}'.format(acc, epoch_loss))